{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def logistic_function(x):\n",
        "    \"\"\"\n",
        "    Computes the logistic (sigmoid) function.\n",
        "    \"\"\"\n",
        "    y = 1 / (1 + np.exp(-x))\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "WLhgGzGG4aRo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_function():\n",
        "\n",
        "    x_scalar = 0\n",
        "    expected_output_scalar = round(1 / (1 + np.exp(0)), 3)\n",
        "    assert round(logistic_function(x_scalar), 3) == expected_output_scalar\n",
        "\n",
        "    x_pos = 2\n",
        "    expected_output_pos = round(1 / (1 + np.exp(-2)), 3)\n",
        "    assert round(logistic_function(x_pos), 3) == expected_output_pos\n",
        "\n",
        "    x_neg = -3\n",
        "    expected_output_neg = round(1 / (1 + np.exp(3)), 3)\n",
        "    assert round(logistic_function(x_neg), 3) == expected_output_neg\n",
        "\n",
        "    x_array = np.array([0, 2, -3])\n",
        "    expected_output_array = np.array([0.5, 0.881, 0.047])\n",
        "    assert np.all(np.round(logistic_function(x_array), 3) == expected_output_array)\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_logistic_function()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FFLanMQ45vI",
        "outputId": "943623ea-f347-4bae-890d-80d5a72fd2f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log Loss Function"
      ],
      "metadata": {
        "id": "MPcHEqmY5BiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes log loss for binary classification\n",
        "    \"\"\"\n",
        "    y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
        "    loss = -(y_true * np.log(y_pred)) - ((1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "O21LTJFz47Tx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Log Loss"
      ],
      "metadata": {
        "id": "uXsZOSbE5Grq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_log_loss():\n",
        "    import numpy as np\n",
        "\n",
        "    assert np.isclose(log_loss(1, 1), 0.0)\n",
        "    assert np.isclose(log_loss(0, 0), 0.0)\n",
        "\n",
        "    y_true = 1\n",
        "    y_pred = 0.8\n",
        "    expected_loss = -(1 * np.log(0.8))\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected_loss)\n",
        "\n",
        "    y_true = 0\n",
        "    y_pred = 0.2\n",
        "    expected_loss = -(1 * np.log(0.8))\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected_loss)\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_log_loss()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTuYFWQ55Hgh",
        "outputId": "3482c666-0c7f-42b4-fc37-f52c212abd1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost Function (Average Loss)"
      ],
      "metadata": {
        "id": "j6u5CVkC5RP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(y_true, y_pred):\n",
        "    assert len(y_true) == len(y_pred)\n",
        "\n",
        "    n = len(y_true)\n",
        "    loss_vec = log_loss(y_true, y_pred)\n",
        "    cost = np.sum(loss_vec) / n\n",
        "\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "BeJgkIFR5R2W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Cost Function"
      ],
      "metadata": {
        "id": "8TtQIc-u5anc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_cost_function():\n",
        "    y_true = np.array([1, 0, 1])\n",
        "    y_pred = np.array([0.9, 0.1, 0.8])\n",
        "\n",
        "    expected_cost = (\n",
        "        (-(1*np.log(0.9)) - (0*np.log(0.1))) +\n",
        "        (-(0*np.log(0.1)) - (1*np.log(0.9))) +\n",
        "        (-(1*np.log(0.8)) - (0*np.log(0.2)))\n",
        "    ) / 3\n",
        "\n",
        "    result = cost_function(y_true, y_pred)\n",
        "\n",
        "    assert np.isclose(result, expected_cost, atol=1e-6), f\"{result} != {expected_cost}\"\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "test_cost_function()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "653fI8BT6CB_",
        "outputId": "bf371290-b790-420b-f07c-d1220d54a734"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost Function with Weights (Logistic Regression)"
      ],
      "metadata": {
        "id": "5S6tBwzY6Po4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def costfunction_logreg(X, y, w, b):\n",
        "    n, d = X.shape\n",
        "\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = logistic_function(z)\n",
        "\n",
        "    cost = cost_function(y, y_pred)\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "2Gv4NgTu6QTM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Calculation"
      ],
      "metadata": {
        "id": "iVx39mcO6UZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, y, w, b):\n",
        "    n, d = X.shape\n",
        "\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = logistic_function(z)\n",
        "\n",
        "    grad_w = -(1/n) * np.dot(X.T, (y - y_pred))\n",
        "    grad_b = -(1/n) * np.sum(y - y_pred)\n",
        "\n",
        "    return grad_w, grad_b\n"
      ],
      "metadata": {
        "id": "GSptULIx6U9a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent (TRAINING)"
      ],
      "metadata": {
        "id": "iwa8-0zd6Yux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False, show_params=True):\n",
        "\n",
        "    cost_history = []\n",
        "    params_history = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "\n",
        "        w -= alpha * grad_w\n",
        "        b -= alpha * grad_b\n",
        "\n",
        "        cost = costfunction_logreg(X, y, w, b)\n",
        "\n",
        "        cost_history.append(cost)\n",
        "        params_history.append((w.copy(), b))\n",
        "\n",
        "        if show_cost and i % 100 == 0:\n",
        "            print(f\"Iteration {i}: Cost = {cost:.6f}\")\n",
        "\n",
        "    return w, b, cost_history, params_history\n"
      ],
      "metadata": {
        "id": "aZbpnSMA6ZUa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction Function"
      ],
      "metadata": {
        "id": "xPSZCDL66df8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(X, w, b, threshold=0.5):\n",
        "    z = np.dot(X, w) + b\n",
        "    y_prob = logistic_function(z)\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "oQSXI_3e6eau"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metrics"
      ],
      "metadata": {
        "id": "JmGUJVWW6iOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(y_true, y_pred):\n",
        "\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "    confusion_matrix = np.array([[TN, FP],\n",
        "                                  [FN, TP]])\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return confusion_matrix, precision, recall, f1_score\n"
      ],
      "metadata": {
        "id": "mFuJx9Zc6jAz"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}